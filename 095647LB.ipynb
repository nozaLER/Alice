{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242171</th>\n",
       "      <td>952</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:23</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:23</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:23</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:24</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:24</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:24</td>\n",
       "      <td>955.0</td>\n",
       "      <td>2013-01-12 08:50:24</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:25</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57157</th>\n",
       "      <td>953</td>\n",
       "      <td>2013-01-12 08:50:25</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:26</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:26</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:26</td>\n",
       "      <td>955.0</td>\n",
       "      <td>2013-01-12 08:50:26</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:27</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:27</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:27</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:28</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>2013-01-12 08:50:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240201</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:28</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:28</td>\n",
       "      <td>954.0</td>\n",
       "      <td>2013-01-12 08:50:28</td>\n",
       "      <td>953.0</td>\n",
       "      <td>2013-01-12 08:50:29</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:29</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:29</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:30</td>\n",
       "      <td>956.0</td>\n",
       "      <td>2013-01-12 08:50:30</td>\n",
       "      <td>957.0</td>\n",
       "      <td>2013-01-12 08:50:31</td>\n",
       "      <td>956.0</td>\n",
       "      <td>2013-01-12 08:50:31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210686</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:31</td>\n",
       "      <td>956.0</td>\n",
       "      <td>2013-01-12 08:50:32</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:32</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:33</td>\n",
       "      <td>955.0</td>\n",
       "      <td>2013-01-12 08:50:33</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:33</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:34</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:35</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:36</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98804</th>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:37</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:37</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:38</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:49</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2013-01-12 08:50:59</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:51:03</td>\n",
       "      <td>812.0</td>\n",
       "      <td>2013-01-12 08:51:03</td>\n",
       "      <td>982.0</td>\n",
       "      <td>2013-01-12 08:51:03</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2013-01-12 08:51:03</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2013-01-12 08:51:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "242171        952 2013-01-12 08:50:22  947.0 2013-01-12 08:50:23  953.0   \n",
       "57157         953 2013-01-12 08:50:25  947.0 2013-01-12 08:50:26  946.0   \n",
       "240201        946 2013-01-12 08:50:28  947.0 2013-01-12 08:50:28  954.0   \n",
       "210686        946 2013-01-12 08:50:31  956.0 2013-01-12 08:50:32  946.0   \n",
       "98804         948 2013-01-12 08:50:37  946.0 2013-01-12 08:50:37  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "242171     2013-01-12 08:50:23  946.0 2013-01-12 08:50:23  947.0   \n",
       "57157      2013-01-12 08:50:26  953.0 2013-01-12 08:50:26  955.0   \n",
       "240201     2013-01-12 08:50:28  953.0 2013-01-12 08:50:29  946.0   \n",
       "210686     2013-01-12 08:50:32  946.0 2013-01-12 08:50:33  955.0   \n",
       "98804      2013-01-12 08:50:38  784.0 2013-01-12 08:50:49   49.0   \n",
       "\n",
       "                         time5  ...               time6  site7  \\\n",
       "session_id                      ...                              \n",
       "21669                      NaT  ...                 NaT    NaN   \n",
       "54843                      NaT  ...                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n",
       "242171     2013-01-12 08:50:24  ... 2013-01-12 08:50:24  953.0   \n",
       "57157      2013-01-12 08:50:26  ... 2013-01-12 08:50:27  953.0   \n",
       "240201     2013-01-12 08:50:29  ... 2013-01-12 08:50:29  946.0   \n",
       "210686     2013-01-12 08:50:33  ... 2013-01-12 08:50:33  946.0   \n",
       "98804      2013-01-12 08:50:59  ... 2013-01-12 08:51:03  812.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "242171     2013-01-12 08:50:24  955.0 2013-01-12 08:50:24  946.0   \n",
       "57157      2013-01-12 08:50:27  946.0 2013-01-12 08:50:27  953.0   \n",
       "240201     2013-01-12 08:50:30  956.0 2013-01-12 08:50:30  957.0   \n",
       "210686     2013-01-12 08:50:34  946.0 2013-01-12 08:50:35  946.0   \n",
       "98804      2013-01-12 08:51:03  982.0 2013-01-12 08:51:03   52.0   \n",
       "\n",
       "                         time9  site10              time10 target  \n",
       "session_id                                                         \n",
       "21669                      NaT     NaN                 NaT      0  \n",
       "54843                      NaT     NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17   946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19   946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22   947.0 2013-01-12 08:50:22      0  \n",
       "242171     2013-01-12 08:50:25   947.0 2013-01-12 08:50:25      0  \n",
       "57157      2013-01-12 08:50:28  1033.0 2013-01-12 08:50:28      0  \n",
       "240201     2013-01-12 08:50:31   956.0 2013-01-12 08:50:31      0  \n",
       "210686     2013-01-12 08:50:36   948.0 2013-01-12 08:50:36      0  \n",
       "98804      2013-01-12 08:51:03    52.0 2013-01-12 08:51:04      0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training and test data sets, change paths if needed\n",
    "\n",
    "\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv('train_sessions.csv',\n",
    "                       index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv('test_sessions.csv',\n",
    "                      index_col='session_id', parse_dates=times)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[sites] = train_df[sites].fillna(0).astype(np.uint16)\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(np.uint16)\n",
    "\n",
    "# Load websites dictionary\n",
    "with open('site_dic.pkl', \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>1786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           min                 max  seconds\n",
       "session_id                                                 \n",
       "21669      2013-01-12 08:05:57 2013-01-12 08:05:57      0.0\n",
       "54843      2013-01-12 08:37:23 2013-01-12 09:07:09   1786.0\n",
       "77292      2013-01-12 08:50:13 2013-01-12 08:50:17      4.0\n",
       "114021     2013-01-12 08:50:17 2013-01-12 08:50:20      3.0\n",
       "146670     2013-01-12 08:50:20 2013-01-12 08:50:22      2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# Find sessions' starting and ending\n",
    "time_df['min'] = full_df[times].min(axis=1)\n",
    "time_df['max'] = full_df[times].max(axis=1)\n",
    "\n",
    "# Calculate sessions' duration in seconds\n",
    "time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# Add start_month feature\n",
    "year_month['start_month'] = full_df['time1'].apply(lambda ts: \n",
    "                                                      100 * ts.year + ts.month).astype('float64')\n",
    "year_month_t = pd.get_dummies(year_month['start_month'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# Add start_month feature\n",
    "month['month'] = full_df['time1'].apply(lambda ts: ts.month).astype('float64')\n",
    "month_t = pd.get_dummies(month['month'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_weeks= pd.DataFrame(index=full_df.index)\n",
    "number_weeks['number_week'] = full_df['time1'].apply(lambda ts: ts.week).astype('float64')\n",
    "number_weeks_t = pd.get_dummies(number_weeks['number_week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## выходные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_end= pd.DataFrame(index=full_df.index)\n",
    "week_end['week_end'] = full_df['time1'].apply(lambda ts: 1 if ts.dayofweek>4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Час"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = pd.DataFrame(index=full_df.index)\n",
    "hour['start_hour'] = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "hour_t = pd.get_dummies(hour['start_hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## День недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week= pd.DataFrame(index=full_df.index)\n",
    "day_of_week['day_of_week'] = full_df['time1'].apply(lambda ts: ts.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week_t = pd.get_dummies(day_of_week['day_of_week']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blyat(t):\n",
    "    if t<11:\n",
    "        return 0\n",
    "    elif t>19:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть дня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_day = pd.DataFrame(index=full_df.index)\n",
    "part_of_day['part_of_day'] = hour['start_hour'].apply(blyat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_day_t = pd.get_dummies(part_of_day['part_of_day']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть дня 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blyat1(t):\n",
    "    if 6<=t<12:\n",
    "        return 0\n",
    "    elif 12<=t<18:\n",
    "        return 1\n",
    "    elif 18<=t<24:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_day1 = pd.DataFrame(index=full_df.index)\n",
    "part_of_day1['part_of_day1'] = hour['start_hour'].apply(blyat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_day_t1 = pd.get_dummies(part_of_day1['part_of_day1']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## уникальный значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_q = pd.DataFrame(index=full_df.index)\n",
    "n_q['uni'] = full_df[sites].replace(0, np.NaN).nunique(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нагло содрал у  [ЮРИЯ](https://www.kaggle.com/kashnitsky/model-validation-in-a-competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2site = {v:k for (k, v) in site_dict.items()}\n",
    "str_train = [' '.join([id2site[idx] for idx in row.values if idx in id2site]) for _, row in train_df[sites].iterrows()]\n",
    "str_test = [' '.join([id2site[idx] for idx in row.values if idx in id2site]) for _, row in test_df[sites].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1, 5),max_features =1600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = vectorizer.fit_transform(np.array(str_train))\n",
    "X_test = vectorizer.transform((str_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =train_df[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Колдуем с признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "time_dur = StandardScaler().fit_transform(time_df[['seconds']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " week_end[['week_end']].values[:idx_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t =np.hstack([#X_train,\n",
    "                   part_of_day_t1.values[:idx_split],\n",
    "                   day_of_week_t.values[:idx_split],\n",
    "                   year_month_t.values[:idx_split],\n",
    "                   number_weeks_t.values[:idx_split],\n",
    "                   time_df[['seconds']].values[:idx_split],\n",
    "                   week_end[['week_end']].values[:idx_split]\n",
    "])\n",
    "                   \n",
    "X_test_t =np.hstack([#X_test,\n",
    "                   part_of_day_t1.values[idx_split:],\n",
    "                   day_of_week_t.values[idx_split:],\n",
    "                   year_month_t.values[idx_split:],\n",
    "                   number_weeks_t.values[idx_split:],\n",
    "                   time_df[['seconds']].values[idx_split:],\n",
    "                   week_end[['week_end']].values[idx_split:] \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 78)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X, y, train_size=0.7, random_states=[1, 13, 42]):\n",
    "    result = []\n",
    "    \n",
    "    for rs in random_states:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=train_size, stratify=y, random_state=rs)\n",
    "        m = clone(model, safe=True)\n",
    "        m.fit(X_train, y_train)\n",
    "        valid_score = m.predict_proba(X_valid)\n",
    "        result.append(roc_auc_score(y_valid, valid_score[:, 1:]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9258525358310348, 0.9201725673616521, 0.9173274470789702]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(LogisticRegression(C=21.55, n_jobs=-1), X_train_t\n",
    "      , y)\n",
    "#[0.9889510370484755, 0.9865306924836754, 0.988063920740623]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9258546730431321, 0.9201912053914738, 0.9173470670711068]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(LogisticRegression(C=15, n_jobs=-1), X_train_t\n",
    "      , y)\n",
    "#[0.9890169440485576, 0.986253971652481, 0.9879412909762284]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9259112417741403, 0.9200752375674907, 0.9172272484145159]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(LogisticRegression(C=10 ,n_jobs=-1), X_train_t\n",
    "      , y)\n",
    "#[0.9890169440485576, 0.986253971652481, 0.9879412909762284]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9256572023470054, 0.9199441744796852, 0.9170828421917245]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(LogisticRegression(C=5 ,n_jobs=-1), X_train_t\n",
    "      , y)\n",
    "#[0.9890169440485576, 0.986253971652481, 0.9879412909762284]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отправляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, X_train, y_train, X_test):\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred_proba = model.predict_proba(X_test)\n",
    "    write_to_submission_file(test_pred_proba[:, 1:], 'result____1_test1.csv')\n",
    "def write_to_submission_file(predicted_labels, out_file, target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels, index = np.arange(1, predicted_labels.shape[0] + 1), columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(LogisticRegression(C=19, n_jobs=-1), X_train_t, y, X_test_t#result__8 0.95647lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 78)\n",
      "(82797, 78)\n"
     ]
    }
   ],
   "source": [
    "make_submission(LogisticRegression(C=12, n_jobs=-1), X_train_t, y, X_test_t)#result__8 0.95647lb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
